According to the classical Church-Turing computability thesis, computation can be modelled on a mathematical function. The machine receives input; it undergoes a sequence of state transitions — moves or legal runs — and yields an output. During the computation, the machine shuts out the environment and accepts no further input until the initial input is processed. In this form, computation can be represented as a logical deduction where to compute means the same as to deduce steps from an initial configuration. Like deduction, the process of computation can then be characterized in terms of how the output — conclusion — is logically contained in the input — the premise — or how the output/conclusion is implied by the input/premise. But if this is all that computation is — algorithmic deduction — then what exactly is gained by it? Computation runs into the same problem that deduction leads to, namely the riddle of epistemic omniscience according to which the total knowledge of an agent can be said to be deductively closed.which If the agent a knows (.K) the proposition p then it knows all its logical consequences q. While such a verdict is absolutely sound and valid in some classical logic heaven, it has no ground in reality. A corresponding computational equivalent of deductions problem of epistemic omniscience is the classical denotational semantics of programming languages, where all that is required to provide meaning to the expression of a language (i.e., the meaning of the program) or to know what the program does, is to know the given structured sets of data types —domains — and the interpretation function that maps those domains to one another.  Here, the puzzling situation is that computation is supposed to yield new information, whereas the classical paradigm suggests a closed logical system wherein the output information is nothing but the input plus a machine that deduces steps from it. From an information-theoretic point of view, no new information is added by computation, and from an epistemic point of view no knowledge is gained by computation.
What the classical account of computation presupposes but does not incorporate as its intrinsic dimension is that which provides the input and consumes the output—namely, the environment. The system or machine becomes the model of what computes, at the expense of keeping the environment in the background. The environment is merely represented as an average behaviour, rather than something that dynamically and actively interacts with the system. But it is only by highlighting the role of the environment that the system’s or machine’s function — input-output mapping — can coherently make sense. Moreover, it is only in the presence of an environment (another system, machine, or agent) that computation can be understood as an increase—rather than mere preservation—of information, hence avoiding the riddle of epistemic omniscience. From this perspective, the environment is no longer a passive ambient space but an active-reactive element to which the system responds by accepting input from it and yielding output which the environment then consumes. In view of the role of the environment in the input-output mapping, the question of computation, rather than being couched in terms of what is a computable function, shifts to the question of how the computation is executed. By bringing the howness of computation into the foreground, the question of computability turns into the question What is computation? — that is, it now concerns the interaction or confrontation of actions between machine and environment.
With the understanding of interaction itself as computation, the system- environment (or player-opponent, machine-network) dynamics can be modelled as a so-called interaction or simply general game. The interaction game differs from game-theoretic account of games in a number of significant ways. It does not require procedural rules or rules that dictate how the game should proceed or what moves/actions should be performed in a given situation.